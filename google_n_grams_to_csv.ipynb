{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "google_n_grams_to_csv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPX82DKKEF1sTu65c+198Cz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewpkitchin/google-n-grams/blob/main/google_n_grams_to_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ye501VJfZEuT"
      },
      "outputs": [],
      "source": [
        "import requests, json, csv, time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1500-2019\n",
        "\n",
        "list_of_dates = []\n",
        "\n",
        "for i in range(0,520):\n",
        "  list_of_dates.append(1500+i)"
      ],
      "metadata": {
        "id": "QlZ5yElcZKr3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# takes a list of grams and date labels and creates a csv where each cell represent the google n-gram percentage for a gram and a year\n",
        "\n",
        "def ngrams_to_csv(csv_name, list_of_ngrams, list_of_dates):\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    list_of_dates.insert(0,'Word')\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "\n",
        "    writer.writerow(list_of_dates)\n",
        "\n",
        "    list_of_dates.pop(0)\n",
        "\n",
        "    # smoothing = 0 means no smoothing, list of copora \n",
        "\n",
        "    for word in list_of_ngrams:\n",
        "      url =f\"https://books.google.com/ngrams/json?content={word}&year_start=1500&year_end=2019&corpus=26&smoothing=0&case_insensitive=case_insensitive\"\n",
        "      resp = requests.get(url)\n",
        "      if resp.ok:\n",
        "        results = json.loads(resp.content)\n",
        "\n",
        "      listOfPercentages = [word] + results[0]['timeseries']\n",
        "\n",
        "      # Writing the n-gram percentages to the csv.\n",
        "\n",
        "      writer.writerow(listOfPercentages)\n",
        "\n",
        "      time.sleep(0.5)"
      ],
      "metadata": {
        "id": "pooTo1lLZMni"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_ngrams = [\"one\", \"Albert Einstein\"]"
      ],
      "metadata": {
        "id": "lrd1SSr5ZSY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrams_to_csv(\"test1.csv\", list_of_ngrams, list_of_dates)"
      ],
      "metadata": {
        "id": "eUBXxRTFZVCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vBvsex_k-84R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# date_indexer(1950,2019) RETURNS [450, 520] \n",
        "\n",
        "def date_indexer(start_date, end_date):\n",
        "  start = start_date-1500\n",
        "  end = end_date-1499\n",
        "  return [start, end]"
      ],
      "metadata": {
        "id": "dBo8mjU5H4Km"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the list results[0]['timeseries'] containing percentages for 1500-2019, average_over_dates(list_of_ngrams, start_date, end_date) returns average of \n",
        "# percentage in the date range \n",
        "\n",
        "def average_over_dates(list_of_ngrams, start_date, end_date):\n",
        "  indexes = date_indexer(start_date, end_date)\n",
        "  sliced_list = list_of_ngrams[indexes[0]:indexes[1]]\n",
        "  average = sum(sliced_list)/len(sliced_list)\n",
        "\n",
        "  return average "
      ],
      "metadata": {
        "id": "_UhT2S7nK6q_"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_percentage_over_range(list_of_ngrams, start_date, end_date):\n",
        "  \n",
        "  holding_list = [] \n",
        "\n",
        "  for gram in list_of_ngrams:\n",
        "        url =f\"https://books.google.com/ngrams/json?content={gram}&year_start=1500&year_end=2019&corpus=26&smoothing=0&case_insensitive=case_insensitive\"\n",
        "        resp = requests.get(url)\n",
        "        if resp.ok:\n",
        "          results = json.loads(resp.content)\n",
        "\n",
        "        holding_list.append(average_over_dates(results[0]['timeseries'],start_date, end_date))\n",
        "\n",
        "        time.sleep(0.2)\n",
        "\n",
        "  average = sum(holding_list)/len(holding_list)\n",
        "\n",
        "  return average"
      ],
      "metadata": {
        "id": "GKHKc9ZS-89h"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entities_and_queries = [[entity, [list of queries]], ... ] \n",
        "\n",
        "def ngrams_averages_to_csv(csv_name, entities_and_queries, start_date, end_date):\n",
        "\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "\n",
        "    writer.writerow(['entity', 'average percentage', 'list of queries'])\n",
        "    \n",
        "    for entry in entities_and_queries:\n",
        "\n",
        "      result = average_percentage_over_range(entry[1], start_date, end_date)\n",
        "\n",
        "      writer.writerow([entry[0], result, entry[1]])"
      ],
      "metadata": {
        "id": "QeH8bfXJb-_z"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "entities_and_queries = [['one',['one two', 'hello everyone']]]\n",
        "\n",
        "ngrams_averages_to_csv('test.csv', entities_and_queries, 1950, 2019)"
      ],
      "metadata": {
        "id": "wdOe-QMRhIoH"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4nk7-aHcpO8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2 "
      ],
      "metadata": {
        "id": "Comx2ELDpPBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# entities_and_queries = [[entity, [perception term, query one, query two, ...], [perception term, query one, query two, ...] ], ... ] \n",
        "\n",
        "def ngrams_averages_to_csv(csv_name, entities_and_queries, start_date, end_date):\n",
        "\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "\n",
        "    keyterms = []\n",
        "\n",
        "    for entry in entities_and_queries:\n",
        "      \n",
        "      for item in entry[1:]:\n",
        "        keyterms.append(item[0])\n",
        "\n",
        "    writer.writerow(['entity'] + keyterms)\n",
        "\n",
        "    holding_list = []\n",
        "\n",
        "    for entry in entities_and_queries:\n",
        "\n",
        "      for item in entry[1:]:\n",
        "        result = average_percentage_over_range(item[1:], start_date, end_date)\n",
        "\n",
        "        holding_list.append(result)\n",
        "\n",
        "      writer.writerow([entry[0]]+holding_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "p6HC7AZfpPER"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "\n",
        "entities_and_queries = [['one',['one two', 'hello everyone'], ['three', 'hello there']]]\n",
        "\n",
        "ngrams_averages_to_csv('test.csv', entities_and_queries, 1950, 2019)"
      ],
      "metadata": {
        "id": "4-LABExwsFct"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}